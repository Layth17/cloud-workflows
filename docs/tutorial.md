# Submitting a Workflow from Scratch

This tutorial aims to walk through the complete steps of taking an
existing workflow (e.g. the CWL and a set of YML inputs) and submit
that workflow on the remote GCS server.

Prerequisites:
1. Acquire original workflow CWL and inputs for cluster
1. Acquire pre-converted WDL equivalent to your CWL from analysis-wdls
1. Write access to your labs GCS bucket
1. gcloud installed and configured locally

The steps are roughly as follows:
1. Upload input files to GCS, generating a new inputs file for them
1. Submit workflow run to the remote server
1. Pull output files generated by the run

# The Docker Image

Each of these steps has an associated script. Some of them require
dependencies to be installed, which means using a Docker container
with bsub.

Currently the docker image is located at
`jackmaruska/cloudize-workflow:latest`, though it's planned to be
moved to a non-personal account eventually.

Spin up an interactive bsub with
```sh
bsub -Is -q general-interactive -G $GROUP -a "docker(jackmaruska/cloudize-workflow:1.0.4)" /bin/bash
```

Within the docker image, scripts are located at /opt, e.g. `/opt/cloudize-workflow.py`

# 0. Set up values

I like to set up my values with environment variables to make it more
readable and commands more copy-paste friendly. This isn't strictly
necessary but hopefully it helps.

```sh
export WORKFLOW_CWL=/storage1/fs1/bga/Active/shared/analysis-workflows/definitions/pipelines/somatic_exome.cwl
export ANALYSIS_WDLS=/scratch1/fs1/oncology/maruska/analysis-wdls
export WORKFLOW_WDL=$ANALYSIS_WDLS/definitions/pipelines/somatic_exome.wdl
export CLUSTER_INPUT=/storage1/fs1/bga/Active/shared/analysis-workflows-example-data/somatic_exome.yaml
export MODIFIED_INPUT=$PWD/somatic_exome_cloud.yaml
export GCS_BUCKET=griffith-lab-cromwell
export CROMWELL_URL=http://35.188.155.31:8000
```

# 1. Processing Input File

```sh
python3 /opt/cloudize-workflow.py $GCS_BUCKET $WORKFLOW_CWL $CLUSTER_INPUT --output=$MODIFIED_INPUT --dryrun=True
```

# 1.5. Modify inputs for CWL to WDL change

The script doesn't have an option to spit out an input file for a
different workflow type, because there are differences between their
inputs. For now this step is to be done manually. Generally what will
change between types for most workflows are

1. Secondary files explicitly included (e.g. bam_bai inputs)
1. Directory type either a single .zip or an Array[File] type
1. Extra inputs to handle lack of JavaScript embedding
1. All inputs specify their workflow as a dot prefix,
   e.g. `normal_sample_name` becomes `somaticExome.normal_sample_name`

For our example of somatic exome, do the following modifications:
1. Add secondary file inputs for reference, bqsr_known_sites,
1. Replace `vep_cache_dir` with `vep_cache_dir_zip: gs://griffith-lab-cromwell/input_data/vep.zip`
1. prepend `somaticExome.` to all top level inputs

# 2. Submit Workflow

Submitting a workflow has two parts, the first is zipping all
dependency workflows together, and the second is sending the submit
request to the server.

Until a change is made to move this to a flag, `submit_workflow.sh`
expects an env var `ANALYSIS_WDLS` to be set to the location of that
directory. Export that if you haven't in step 0.

```sh
export ANALYSIS_WDLS=/scratch1/fs1/oncology/maruska/analysis-wdls
sh /opt/submit_workflow.sh $WORKFLOW_WDL $MODIFIED_INPUT
```

# 3. Checking on the Workflow

We're outside the bsub container now, back on the local machine.

## Check workflow status

Several options here, primarily either swagger, cromshell, or curl

Swagger: http://35.188.155.31:8000/swagger/index.html?url=/swagger/cromwell.yaml#/Workflows/status
Add workflow-id and submit

CURL:
```
curl "$CROMWELL_URL/api/workflows/v1/$WORKFLOW_ID/status"
```

## Cromwell server logs

We haven't found a good way to access cromwell server logs that
_doesn't_ involve just SSHing in to the server and following the logs
with journalctl, so... let's do that.

SSH in to the server using gcloud to leverage their authentication.
This requires gcloud be installed/configured and you have SSH access to the VM.
```
gcloud beta compute ssh --zone "us-central1-c" "cromwell" --project "griffith-lab"
```

Once inside the VM, just run the command
```
journalctl -u cromwell | less
```

Do any variations you'd like with this, like follow with `-f` or
`grep`. Just try not to dump everything out because it may be a large
amount.

Issues like parsing or bad requirements will be logged here, but most
likely a runtime issue will happen in the logs of a specific
task. Usually you'll find just above a large stacktrace an error
message with a `gs://` path to the `.log` or `stderr` of a specific
task.

### Checking task specific logs

Most issues end up happening inside the runtime of a task. The easiest
way to see these is to pull the `.log` or `stderr` of that
task. Typically the way to find the relevant one is to check the
server logs via SSH. If that's not possible, there are other ways to
find the information but they're pretty hacky. You could use the
timing diagram, or knowledge of the workflow, to find out the last
tasks that ran and search for which failed, time consuming and tedious
though.

When you have a `gs://` file you want to pull from GCS, just use
gsutil to interact with it. `gsutil cp gs://your/file/here
local_version` to download a local copy. `gsutil cat
gs://your/file/here` to print its contents. Plenty other options if
you fiddle with `gsutil`, though these are the main two for inspecting
existing files.

# 4. Pull Output Files

Back on the cluster, in our docker container, we'll use the
pull_outputs.py script to download our output files back to WashU
storage.

```sh
python3 /opt/pull_outputs.py $WORKFLOW_ID --output=/path/to/destination
```

The --output flag is optional, and if omitted will create an
`./outputs` directory to store files. The script should print a status
for each file, either "Downloading" with its size and paths to both
cloud location and target destination, or ERROR if the source doesn't
exist (unsure why this happens or what it means, but I've seen it
happen). On repeated calls, the script silently skips existing files.

# Appendix

## Finding your labs GCS bucket

The Cromwell server can only use buckets which are in its
configuration file. To see what is configured for your specific lab,
go to the `cloud-workflows/jinja/cromwell.conf` file, and locate the
path `backend.provider.<YOUR_LAB>.config.root`, whose value will be
`gs://<YOUR_BUCKET>/<subpath>`.


## Saturating pipe on uploads

When uploading input files to GCS form a bsub job, add to your
`rusage` the value `internet2_upload_mbps=5000`. Or lower if you're
worried about leaving room for others. This removes an overhead cap
and should help you get maximum bandwidth on WashU's pipe to Google.
